## RoadMap-to-A-Llmer

### Papers
| Year | Paper | Project | Code | Notes |
| :----: | :----: | :----: | :----: | :----: |
| [1706.03762](https://arxiv.org/abs/1706.03762) | [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) | None | [Code](Attention_is_All_You_Need/attention_is_All_You_Need.py) | [Transformer](Attention_is_All_You_Need/attention-is-all-you-need.md) |


### Reference
[machine-learning-notes](https://github.com/luweiagi/machine-learning-notes)  
[pytorch-seq2seq](https://github.com/bentrevett/pytorch-seq2seq)